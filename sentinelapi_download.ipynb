{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data from Sentinel hub\n",
    "First part of the project is to build a notebook to download satelite images taken by sentinel satellites.  \n",
    "The data is available both online and through the Sentinel API.  \n",
    "  \n",
    "[Sentinel-2](https://apihub.copernicus.eu/apihub) - available if you register to sentinel hub (free)  \n",
    "[Sentinel-5](https://s5phub.copernicus.eu/dhus) - available without registration (free)  \n",
    "    \n",
    "In this notebook I will provide a code to download both `Sentinel-5` and `Sentinel-2` satellite images. \n",
    "   \n",
    "Let's start with Importing the necessary libraries. Keep in mind that `rasterio` is `gdal` dependant.\n",
    "\n",
    "### Sentinel 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "import glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S5 hub is free for everyone with guest credentials\n",
    "api = SentinelAPI('s5pguest', 's5pguest', 'https://s5phub.copernicus.eu/dhus')\n",
    "# set area of interest == Lithuania\n",
    "footprint = geojson_to_wkt(read_geojson('mapLT.geojson'))\n",
    "# set dates that you want to search for\n",
    "init_day = date(2023, 2, 1)\n",
    "end_day = date(2023, 3, 1)\n",
    "# set the initial orbit that you want to follow\n",
    "init_day_orbit = 27453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orbit_nr_counter(first_day, last_day, initial_orbit_nr):\n",
    "    '''\n",
    "    Given time interval and first number of orbit returns a list containing orbit numbers.\n",
    "    Input:\n",
    "        first_day : first day to look for the values \n",
    "        last_day : end day to look for the values\n",
    "        initial_orbit_nr : initial orbit number\n",
    "    Output: list\n",
    "    '''\n",
    "    n = (last_day-first_day).days  # Number of days to look for\n",
    "    increment = 14  # Amount to increment by each day (every fifth day +1)\n",
    "    orbit_numbers = [initial_orbit_nr] # first day is the initial orbit, from here, we will increment the count\n",
    "    count = 0\n",
    "    # let's generate the orbit_numbers list to use in api search\n",
    "    for i in range(1, n + 1):\n",
    "        if i % 5 == 0:\n",
    "            count += 1\n",
    "            orbit_numbers.append((i * increment) + 1 + initial_orbit_nr)\n",
    "        else:\n",
    "            orbit_numbers.append((i * increment) + count + initial_orbit_nr)\n",
    "\n",
    "    return orbit_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's get the orbit numbers that we will be looking for\n",
    "orbit_numbers = orbit_nr_counter(init_day, end_day, init_day_orbit)\n",
    "# then let's search for products available in the sentinel api, given the footprint(area)\n",
    "products = api.query(footprint, \n",
    "                    date = (init_day, end_day),\n",
    "                    platformname = 'Sentinel-5',\n",
    "                    producttype = 'L2__NO2___')\n",
    "# return a df to check data easily\n",
    "products_df = api.to_dataframe(products)\n",
    "# filter the necessary orbits and return a list of ID's\n",
    "products_list = products_df[products_df.orbitnumber.isin(orbit_numbers)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading S5P_OFFL_L2__NO2____20230226T092559_20230226T110729_27836_03_020400_20230228T012659.nc: 100%|██████████| 599M/599M [05:12<00:00, 1.92MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230225T094454_20230225T112625_27822_03_020400_20230227T015410.nc: 100%|██████████| 605M/605M [05:05<00:00, 1.98MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230223T084116_20230223T102246_27793_03_020400_20230225T004111.nc: 100%|██████████| 577M/577M [04:56<00:00, 1.95MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230222T090012_20230222T104142_27779_03_020400_20230224T011420.nc: 100%|██████████| 601M/601M [04:05<00:00, 2.44MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230221T091907_20230221T110038_27765_03_020400_20230223T013507.nc: 100%|██████████| 599M/599M [03:48<00:00, 2.63MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230220T093803_20230220T111934_27751_03_020400_20230222T015319.nc: 100%|██████████| 603M/603M [03:57<00:00, 2.54MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230218T083425_20230218T101555_27722_03_020400_20230220T004256.nc: 100%|██████████| 601M/601M [04:06<00:00, 2.44MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230217T085321_20230217T103451_27708_03_020400_20230219T010552.nc: 100%|██████████| 603M/603M [05:06<00:00, 1.97MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230216T091217_20230216T105347_27694_03_020400_20230218T013742.nc: 100%|██████████| 605M/605M [04:32<00:00, 2.22MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230215T093113_20230215T111243_27680_03_020400_20230217T015810.nc: 100%|██████████| 606M/606M [03:56<00:00, 2.57MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230213T082735_20230213T100905_27651_03_020400_20230215T003549.nc: 100%|██████████| 601M/601M [04:48<00:00, 2.09MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230212T084631_20230212T102801_27637_03_020400_20230214T005539.nc: 100%|██████████| 602M/602M [04:31<00:00, 2.21MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230211T090527_20230211T104658_27623_03_020400_20230213T011757.nc: 100%|██████████| 602M/602M [04:51<00:00, 2.06MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230210T092423_20230210T110554_27609_03_020400_20230212T013903.nc: 100%|██████████| 604M/604M [03:13<00:00, 3.12MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230209T080149_20230209T094320_27594_03_020400_20230211T000655.nc: 100%|██████████| 596M/596M [05:13<00:00, 1.90MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230208T082046_20230208T100216_27580_03_020400_20230210T003108.nc: 100%|██████████| 599M/599M [03:57<00:00, 2.52MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230207T083942_20230207T102112_27566_03_020400_20230209T005309.nc: 100%|██████████| 599M/599M [04:05<00:00, 2.44MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230206T085838_20230206T104009_27552_03_020400_20230208T011325.nc: 100%|██████████| 602M/602M [04:19<00:00, 2.32MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230205T091735_20230205T105905_27538_03_020400_20230207T012634.nc: 100%|██████████| 577M/577M [04:09<00:00, 2.31MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230204T093631_20230204T111802_27524_03_020400_20230206T014821.nc: 100%|██████████| 601M/601M [04:31<00:00, 2.22MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230203T081358_20230203T095528_27509_03_020400_20230205T002859.nc: 100%|██████████| 600M/600M [04:33<00:00, 2.20MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230202T083254_20230202T101424_27495_03_020400_20230204T005218.nc: 100%|██████████| 601M/601M [04:49<00:00, 2.08MB/s] \n",
      "Downloading S5P_OFFL_L2__NO2____20230201T085151_20230201T103321_27481_03_020400_20230203T011437.nc: 100%|██████████| 604M/604M [04:59<00:00, 2.02MB/s] \n"
     ]
    }
   ],
   "source": [
    "# checking if product is online and downloading if so\n",
    "for raster in products_list:\n",
    "    if api.is_online(raster):\n",
    "        api.download(raster, directory_path='sentinel_data/sentinel5/no2 files', checksum=False)\n",
    "    else:\n",
    "        print(\"This tile is not available\" + str(raster))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 2\n",
    "\n",
    "Similar to previous example, we will use the sentinel api to retrieve Sentinel-2 data. Instead of collecting scanlines, here, we search for raster tiles that covers the country map which is provided in ` geojson ` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days for which you want to fetch the data\n",
    "\n",
    "begin_date = date(2022, 8, 3)\n",
    "end_date = date(2022, 10, 10)\n",
    "# your credentials to connect to sentinel hub\n",
    "api = SentinelAPI('dontat', 'Uqga2N2RYbRDgYy', 'https://apihub.copernicus.eu/apihub')\n",
    "# api = SentinelAPI('#user', '#password', 'https://apihub.copernicus.eu/apihub')\n",
    "# set area of interest == Lithuania\n",
    "footprint = geojson_to_wkt(read_geojson('mapLT.geojson'))\n",
    "# define a list of raster tiles that cover the country\n",
    "LT_tiles = ['34VDH','34UDG','34VEH','34UEG',\n",
    "            '34UEF','34VFH','34UFG','34UFF',\n",
    "            '34UFE','35VLC','35ULB','35ULA',\n",
    "            '35ULV','35VMC','35UMB','35UMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all tiles with less than 25% cloud coverage\n",
    "# L2A products provide bottom of atmosphere reflectances in cartographic geometry.\n",
    "\n",
    "products = api.query(footprint, \n",
    "                    date = (begin_date, end_date),\n",
    "                    platformname = 'Sentinel-2',\n",
    "                    processinglevel = 'Level-2A',\t\n",
    "                    cloudcoverpercentage = (0, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should be 16 tiles to cover Lithuania, now we have: 77\n"
     ]
    }
   ],
   "source": [
    "# convert to Pandas DataFrame\n",
    "products_df = api.to_dataframe(products)\n",
    "# filter most recent products with least coulds\n",
    "products_df = products_df.sort_values(['cloudcoverpercentage', 'ingestiondate'], ascending=[True, True])\n",
    "# define unique tiles\n",
    "products_df = products_df[products_df['tileid'].isin(LT_tiles)].drop_duplicates(subset='tileid', keep='first', inplace=False)\n",
    "print(\"should be 16 tiles to cover Lithuania, now we have:\",len(products_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if tile is online and download if so\n",
    "# data will be downloaded in .zip format\n",
    "# keep in mind that raster might not contain a full image, so you can check the precise image and download it manually @ https://scihub.copernicus.eu/dhus/#/home\n",
    "for tile in products_df.index:\n",
    "    if api.is_online(tile):\n",
    "        api.download(tile, directory_path='sentinel_data/sentinel2/s2 tiles', checksum=False)\n",
    "    else:\n",
    "        print(\"This tile is not available\" + str(tile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you are not looking for single \"good\" tile, you can download all tiles from the database\n",
    "## this is what you should do if you want to create a completely cloud free s2 image using several images\n",
    "# api.download_all(products_df.index, directory_path='sentinel_data/sentinel2/s2 tiles', checksum=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75116fd7b35fe6d1d444c3de7b4ffbb5c0e1f0d46e1613217ad09353be51cf5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
